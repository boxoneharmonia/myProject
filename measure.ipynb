{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07890bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.net import build_model\n",
    "from src.utils import set_all_seeds\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3a5036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Test on device cuda:0\n",
      "INFO:__main__:Random seed value: 42\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "if config.use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "logger.info(f\"Test on device {device}\")\n",
    "\n",
    "set_all_seeds(config)\n",
    "logger.info(f\"Random seed value: {config.seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e614cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(config)\n",
    "weight_path = os.path.join(config.weight_dir, config.weight_name + \".pth\")\n",
    "if os.path.exists(weight_path):\n",
    "    logger.info(f\"Loading pretrained weights from {weight_path}\")\n",
    "    model.load_state_dict(torch.load(weight_path, map_location='cpu'), strict=False)\n",
    "else:\n",
    "    logger.warning(f\"Pretrained weights not found at {weight_path}\")\n",
    "    exit(0)    \n",
    "\n",
    "model.eval()\n",
    "model.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def measure(model, root_dir, log_dir, config, device):\n",
    "    transform_base = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])      \n",
    "    img_dir = os.path.join(root_dir, 'img')\n",
    "    csv_path = os.path.join(root_dir, 'data', 'trajectory.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    image_files = sorted([f for f in os.listdir(img_dir) if f.endswith('_pos.png')])\n",
    "    num_timestamps = len(image_files)\n",
    "    vx_results = np.full((num_timestamps, num_timestamps), np.nan)\n",
    "    vy_results = np.full((num_timestamps, num_timestamps), np.nan)\n",
    "    vz_results = np.full((num_timestamps, num_timestamps), np.nan)\n",
    "    num_windows = num_timestamps - config.max_seq_len + 1\n",
    "    for i in tqdm(range(num_windows), desc=\"Measuring\"):\n",
    "        pos_images = []\n",
    "        neg_images = []\n",
    "        traj_list = []\n",
    "        for j in range(config.max_seq_len):\n",
    "            frame_idx = i + j\n",
    "            frame_name = str(frame_idx).zfill(4)\n",
    "            pos_image_path = os.path.join(img_dir, f'{frame_name}_pos.png')\n",
    "            neg_image_path = os.path.join(img_dir, f'{frame_name}_neg.png')\n",
    "            pos_image = Image.open(pos_image_path).convert('L')\n",
    "            neg_image = Image.open(neg_image_path).convert('L')\n",
    "            pos_image = transform_base(pos_image)\n",
    "            neg_image = transform_base(neg_image)\n",
    "            pos_images.append(pos_image)\n",
    "            neg_images.append(neg_image)\n",
    "            data = df.iloc[frame_idx, -6:].to_numpy()\n",
    "            data_tensor = torch.tensor(data).float()\n",
    "            traj_list.append(data_tensor)\n",
    "            \n",
    "            # It selects the last 6 columns of the dataframe row at index frame_idx\n",
    "            \n",
    "        x_pos_seq = torch.stack(pos_images) \n",
    "        x_neg_seq = torch.stack(neg_images)        \n",
    "        x_seq = torch.cat([x_pos_seq, x_neg_seq], dim=1).unsqueeze(0)\n",
    "        traj_seq = torch.stack(traj_list).unsqueeze(0)\n",
    "\n",
    "        x_seq = x_seq.to(device)\n",
    "        traj_seq = traj_seq.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(x_seq, traj_seq)\n",
    "\n",
    "        velocities = output[0, :, 3:6].detach().cpu().numpy()\n",
    "        vx_results[i, i : i + config.max_seq_len] = velocities[:, 0]\n",
    "        vy_results[i, i : i + config.max_seq_len] = velocities[:, 1]\n",
    "        vz_results[i, i : i + config.max_seq_len] = velocities[:, 2]\n",
    "        \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    pd.DataFrame(vx_results).to_csv(os.path.join(log_dir, 'predicted_vx.csv'), index=False, header=False)\n",
    "    pd.DataFrame(vy_results).to_csv(os.path.join(log_dir, 'predicted_vy.csv'), index=False, header=False)\n",
    "    pd.DataFrame(vz_results).to_csv(os.path.join(log_dir, 'predicted_vz.csv'), index=False, header=False)\n",
    "    \n",
    "    print(f\"Measurement finished. Predicted velocity matrices saved in {log_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ac4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(log_dir):\n",
    "    \"\"\"\n",
    "    加载预测矩阵，计算每列的平均值，并保存最终的轨迹。\n",
    "    \"\"\"\n",
    "    print(\"Analyzing prediction matrices...\")\n",
    "    \n",
    "    try:\n",
    "        vx_df = pd.read_csv(os.path.join(log_dir, 'predicted_vx.csv'), header=None)\n",
    "        vy_df = pd.read_csv(os.path.join(log_dir, 'predicted_vy.csv'), header=None)\n",
    "        vz_df = pd.read_csv(os.path.join(log_dir, 'predicted_vz.csv'), header=None)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Prediction files not found in {log_dir}. Please run measure() first.\")\n",
    "        return\n",
    "\n",
    "    # --- 核心计算：对每一列求平均值 ---\n",
    "    # axis=0 表示沿着列的方向操作。pandas会自动忽略NaN。\n",
    "    final_vx = vx_df.mean(axis=0)\n",
    "    final_vy = vy_df.mean(axis=0)\n",
    "    final_vz = vz_df.mean(axis=0)\n",
    "\n",
    "    # --- 组合成最终的轨迹DataFrame ---\n",
    "    final_trajectory_df = pd.DataFrame({\n",
    "        'vx_final': final_vx,\n",
    "        'vy_final': final_vy,\n",
    "        'vz_final': final_vz\n",
    "    })\n",
    "\n",
    "    # --- 保存最终结果 ---\n",
    "    output_path = os.path.join(log_dir, 'final_estimated_velocity.csv')\n",
    "    final_trajectory_df.to_csv(output_path, index_label='timestamp_idx')\n",
    "    \n",
    "    print(f\"Final estimated velocity trajectory saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './dataset/test/0028_4'\n",
    "log_dir = './log/test/0028_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure(model, root_dir, log_dir, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing prediction matrices...\n",
      "Final estimated velocity trajectory saved to ./log/test/0028_4/final_estimated_velocity.csv\n"
     ]
    }
   ],
   "source": [
    "analyze_results(log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
