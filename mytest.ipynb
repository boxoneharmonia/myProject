{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4a81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.net import EventBERTMLM\n",
    "from config import config\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001d978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 初始化配置 ---\n",
      "--- 实例化 Backbone 模型 ---\n",
      "\n",
      "--- 准备模拟输入数据 ---\n",
      "模拟输入 x_pos 形状: torch.Size([1, 30, 3, 200, 200])\n",
      "模拟输入 x_neg 形状: torch.Size([1, 30, 3, 200, 200])\n",
      "\n",
      "--- 执行模型前向传播 ---\n",
      "==============================================================================================================\n",
      "Layer (type:depth-idx)                                       Output Shape              Param #\n",
      "==============================================================================================================\n",
      "EventBERTMLM                                                 [1, 7, 3, 200, 200]       768\n",
      "├─EventImg2Token: 1-1                                        [1, 270, 768]             --\n",
      "│    └─Sequential: 2-1                                       [30, 1024, 13, 13]        --\n",
      "│    │    └─ConvDw: 3-1                                      [30, 32, 100, 100]        193\n",
      "│    │    └─ConvDw: 3-2                                      [30, 128, 50, 50]         4,704\n",
      "│    │    └─ConvDw: 3-3                                      [30, 512, 25, 25]         67,968\n",
      "│    │    └─ConvDw: 3-4                                      [30, 1024, 13, 13]        531,968\n",
      "│    └─Sequential: 2-2                                       [30, 1024, 13, 13]        --\n",
      "│    │    └─ConvDw: 3-5                                      [30, 32, 100, 100]        193\n",
      "│    │    └─ConvDw: 3-6                                      [30, 128, 50, 50]         4,704\n",
      "│    │    └─ConvDw: 3-7                                      [30, 512, 25, 25]         67,968\n",
      "│    │    └─ConvDw: 3-8                                      [30, 1024, 13, 13]        531,968\n",
      "│    └─Sequential: 2-3                                       [1, 270, 768]             --\n",
      "│    │    └─MLP_base: 3-9                                    [1, 270, 768]             8,660,736\n",
      "│    │    └─LayerNormCompatible: 3-10                        [1, 270, 768]             1,536\n",
      "├─Transformer: 1-2                                           [1, 270, 768]             208,128\n",
      "│    └─Sequential: 2-4                                       [1, 271, 768]             --\n",
      "│    │    └─Block: 3-11                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-12                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-13                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-14                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-15                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-16                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-17                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-18                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-19                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-20                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-21                                      [1, 271, 768]             7,094,016\n",
      "│    │    └─Block: 3-22                                      [1, 271, 768]             7,094,016\n",
      "│    └─Sequential: 2-5                                       [1, 271, 768]             --\n",
      "│    │    └─MLP_base: 3-23                                   [1, 271, 768]             1,182,720\n",
      "│    │    └─LayerNormCompatible: 3-24                        [1, 271, 768]             1,536\n",
      "├─Token2EventImg: 1-3                                        [1, 7, 3, 48, 48]         --\n",
      "│    └─Sequential: 2-6                                       [1, 63, 512]              --\n",
      "│    │    └─MLP_base: 3-25                                   [1, 63, 512]              985,856\n",
      "│    │    └─LayerNormCompatible: 3-26                        [1, 63, 512]              1,024\n",
      "│    └─Sequential: 2-7                                       [7, 6, 48, 48]            --\n",
      "│    │    └─deConv: 3-27                                     [7, 256, 6, 6]            1,323,776\n",
      "│    │    └─deConv: 3-28                                     [7, 64, 12, 12]           94,784\n",
      "│    │    └─deConv: 3-29                                     [7, 64, 24, 24]           80,384\n",
      "│    │    └─deConv: 3-30                                     [7, 64, 48, 48]           80,384\n",
      "│    │    └─Conv2d: 3-31                                     [7, 6, 48, 48]            3,462\n",
      "│    │    └─Tanh: 3-32                                       [7, 6, 48, 48]            --\n",
      "==============================================================================================================\n",
      "Total params: 98,962,952\n",
      "Trainable params: 98,962,952\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 10.67\n",
      "==============================================================================================================\n",
      "Input size (MB): 28.80\n",
      "Forward/backward pass size (MB): 1781.44\n",
      "Params size (MB): 395.02\n",
      "Estimated Total Size (MB): 2205.25\n",
      "==============================================================================================================\n",
      "\n",
      "--- 测试完成 ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 初始化配置 ---\")\n",
    "\n",
    "print(\"--- 实例化 Backbone 模型 ---\")\n",
    "model = EventBERTMLM(config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n--- 准备模拟输入数据 ---\")\n",
    "batch_size = 1\n",
    "seq_len = 30 # 确保 seq_len <= config.max_seq_len\n",
    "input_channels = 3\n",
    "input_height = 200\n",
    "input_width = 200\n",
    "\n",
    "# 模拟正负事件图像序列\n",
    "# (batch_size, seq_len, C, H, W)\n",
    "mock_x_pos = torch.randn(batch_size, seq_len, input_channels, input_height, input_width).to(device)\n",
    "mock_x_neg = torch.randn(batch_size, seq_len, input_channels, input_height, input_width).to(device)\n",
    "\n",
    "print(f\"模拟输入 x_pos 形状: {mock_x_pos.shape}\")\n",
    "print(f\"模拟输入 x_neg 形状: {mock_x_neg.shape}\")\n",
    "\n",
    "print(\"\\n--- 执行模型前向传播 ---\")\n",
    "summary(model, input_data=[mock_x_pos, mock_x_neg], verbose=1)\n",
    "\n",
    "print(\"\\n--- 测试完成 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd25e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del mock_x_pos\n",
    "del mock_x_neg \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ModernBertModel, ModernBertConfig\n",
    "\n",
    "# Initializing a ModernBert style configuration\n",
    "configuration = ModernBertConfig()\n",
    "\n",
    "# Initializing a model from the modernbert-base style configuration\n",
    "model = ModernBertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.randperm(10)[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob # 用于文件路径匹配\n",
    "\n",
    "class EventSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_len=20, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 包含所有序列文件夹的根目录 (e.g., 'train/').\n",
    "            seq_len (int): 每个样本的序列长度。\n",
    "            transform (callable, optional): 应用于每张图像的转换。\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        print(\"正在扫描数据集并创建样本索引...\")\n",
    "        \n",
    "        # 1. 遍历根目录下的所有序列文件夹\n",
    "        # 使用 sorted 确保每次运行的顺序一致\n",
    "        sequence_folders = sorted(glob.glob(os.path.join(root_dir, '*/')))\n",
    "        \n",
    "        for seq_folder in sequence_folders:\n",
    "            img_dir = os.path.join(seq_folder, 'img')\n",
    "            if not os.path.isdir(img_dir):\n",
    "                continue\n",
    "            \n",
    "            # 2. 获取该序列文件夹下所有正事件图像的路径\n",
    "            # 我们只需要正事件图像来确定总帧数和文件名格式\n",
    "            pos_image_paths = sorted(glob.glob(os.path.join(img_dir, '*_pos.png')))\n",
    "            \n",
    "            num_frames = len(pos_image_paths)\n",
    "            \n",
    "            # 3. 如果序列长度不足以创建一个样本，则跳过\n",
    "            if num_frames < self.seq_len:\n",
    "                print(f\"警告：序列 {seq_folder} 帧数 ({num_frames}) 小于 seq_len ({self.seq_len})，已跳过。\")\n",
    "                continue\n",
    "                \n",
    "            # 4. 使用滑动窗口创建样本索引\n",
    "            # 起始帧的索引可以从 0 到 num_frames - seq_len\n",
    "            for start_idx in range(num_frames - self.seq_len + 1):\n",
    "                # 将 (序列文件夹路径, 起始帧索引) 作为元组添加到样本列表中\n",
    "                self.samples.append((img_dir, start_idx))\n",
    "                \n",
    "        if not self.samples:\n",
    "            raise RuntimeError(f\"在目录 '{root_dir}' 中未找到任何有效的样本。请检查文件结构和路径。\")\n",
    "            \n",
    "        print(f\"数据集扫描完成。共找到 {len(self.samples)} 个样本。\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中样本的总数。\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取索引为idx的样本。\n",
    "        \n",
    "        Args:\n",
    "            idx (int): 样本的索引。\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (x_pos_seq, x_neg_seq)\n",
    "                   - x_pos_seq: Tensor, shape (seq_len, C, H, W)\n",
    "                   - x_neg_seq: Tensor, shape (seq_len, C, H, W)\n",
    "        \"\"\"\n",
    "        # 1. 从预处理好的样本列表中获取信息\n",
    "        img_dir, start_idx = self.samples[idx]\n",
    "        \n",
    "        pos_images = []\n",
    "        neg_images = []\n",
    "        \n",
    "        # 2. 从 start_idx 开始，加载连续 seq_len 长的图像\n",
    "        for i in range(self.seq_len):\n",
    "            frame_idx = start_idx + i\n",
    "            \n",
    "            # 构建正负事件图像的文件名\n",
    "            # 假设文件名为 0000_pos.png, 0001_pos.png ...\n",
    "            # 使用 f-string 和 zfill 来格式化文件名\n",
    "            frame_name_base = str(frame_idx).zfill(4) # 例如, 5 -> \"0005\"\n",
    "            pos_img_name = f\"{frame_name_base}_pos.png\"\n",
    "            neg_img_name = f\"{frame_name_base}_neg.png\"\n",
    "            \n",
    "            pos_img_path = os.path.join(img_dir, pos_img_name)\n",
    "            neg_img_path = os.path.join(img_dir, neg_img_name)\n",
    "            \n",
    "            # 加载图像\n",
    "            try:\n",
    "                pos_image = Image.open(pos_img_path).convert('RGB')\n",
    "                neg_image = Image.open(neg_img_path).convert('RGB')\n",
    "            except FileNotFoundError:\n",
    "                print(f\"错误：文件未找到于 {pos_img_path} 或 {neg_img_path}\")\n",
    "                # 返回空张量或进行其他错误处理\n",
    "                return torch.empty(self.seq_len, 3, 200, 200), torch.empty(self.seq_len, 3, 200, 200)\n",
    "            \n",
    "            # 应用 transform\n",
    "            if self.transform:\n",
    "                pos_image = self.transform(pos_image)\n",
    "                neg_image = self.transform(neg_image)\n",
    "            \n",
    "            pos_images.append(pos_image)\n",
    "            neg_images.append(neg_image)\n",
    "            \n",
    "        # 3. 将图像列表堆叠成一个序列张量\n",
    "        # pos_images 是一个包含 seq_len 个 (C, H, W) 张量的列表\n",
    "        # torch.stack 会将它们堆叠成 (seq_len, C, H, W)\n",
    "        x_pos_seq = torch.stack(pos_images)\n",
    "        x_neg_seq = torch.stack(neg_images)\n",
    "        \n",
    "        return x_pos_seq, x_neg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b25cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_test.py\n",
    "if __name__ == '__main__':\n",
    "    # 定义图像预处理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 将 PIL Image 转换为 Tensor，并将像素值从 [0, 255] 缩放到 [0.0, 1.0]\n",
    "        # transforms.Resize((200, 200)), # 如果你的图像尺寸不是200x200，取消注释\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # 归一化到 [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # 数据集根目录\n",
    "    dataset_root = './dataset/train' # 假设你的 train 文件夹在当前目录下\n",
    "    sequence_length = 20\n",
    "    batch_size = 1\n",
    "\n",
    "    # 实例化数据集\n",
    "    train_dataset = EventSequenceDataset(\n",
    "        root_dir=dataset_root, \n",
    "        seq_len=sequence_length, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # 实例化 DataLoader\n",
    "    # shuffle=True 会打乱所有 (101 * 28) 个样本的顺序，这正是我们想要的\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4, # 使用多个子进程加载数据以提高效率\n",
    "        pin_memory=True # 如果使用GPU，这可以加速数据从CPU到GPU的传输\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- 开始从 DataLoader 中取出一个批次的数据 ---\")\n",
    "    \n",
    "    # 从迭代器中获取一个批次\n",
    "    try:\n",
    "        x_pos_batch, x_neg_batch = next(iter(train_loader))\n",
    "        \n",
    "        print(f\"成功取出一个批次！\")\n",
    "        print(f\"x_pos_batch 的形状: {x_pos_batch.shape}\")\n",
    "        print(f\"x_neg_batch 的形状: {x_neg_batch.shape}\")\n",
    "\n",
    "        # 验证形状\n",
    "        expected_shape = (batch_size, sequence_length, 3, 200, 200)\n",
    "        if x_pos_batch.shape == expected_shape and x_neg_batch.shape == expected_shape:\n",
    "            print(\"✅ 批次形状符合预期！\")\n",
    "        else:\n",
    "            print(\"❌ 批次形状不匹配。\")\n",
    "            \n",
    "    except StopIteration:\n",
    "        print(\"错误：DataLoader 为空，无法取出数据。请检查数据集路径和内容。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "class EventSequenceDataset(Dataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        self.root_dir = config.dataset_root\n",
    "        self.sequence_length = config.max_seq_len\n",
    "        self.transform = transform\n",
    "        self.transform_base = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])      \n",
    "\n",
    "        self.samples = []\n",
    "        sequence_folders = sorted(glob.glob(os.path.join(self.root_dir, '*/')))\n",
    "\n",
    "        for folder in sequence_folders:\n",
    "            img_dir = os.path.join(folder, 'img')\n",
    "            pos_image_paths = sorted(glob.glob(os.path.join(img_dir, '*_pos.png')))\n",
    "            num_images = len(pos_image_paths)\n",
    "            for start_idx in range(num_images - self.sequence_length + 1):\n",
    "                self.samples.append((img_dir, start_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_dir, start_idx = self.samples[idx]\n",
    "        pos_images = []\n",
    "        neg_images = []\n",
    "        if self.transform is not None:\n",
    "            apply_augmentation = torch.rand(1) < 0.5\n",
    "            angle = torch.randint(0, 4, (1,)).item() * 90 if apply_augmentation else 0\n",
    "            flip = torch.randint(0, 3, (1,)).item() if apply_augmentation else 0\n",
    "        else:\n",
    "            apply_augmentation = False\n",
    "\n",
    "        for i in range(self.sequence_length):\n",
    "            frame_idx = start_idx + i\n",
    "            frame_name = str(frame_idx).zfill(4)\n",
    "            pos_image_path = os.path.join(img_dir, f'{frame_name}_pos.png')\n",
    "            neg_image_path = os.path.join(img_dir, f'{frame_name}_neg.png')\n",
    "            pos_image = Image.open(pos_image_path).convert('RGB')\n",
    "            neg_image = Image.open(neg_image_path).convert('RGB')\n",
    "            if apply_augmentation and self.transform is not None:\n",
    "                pos_image = self.transform(pos_image, angle, flip)\n",
    "                neg_image = self.transform(neg_image, angle, flip)\n",
    "            else:\n",
    "                pos_image = self.transform_base(pos_image)\n",
    "                neg_image = self.transform_base(neg_image)\n",
    "            pos_images.append(pos_image)\n",
    "            neg_images.append(neg_image)\n",
    "\n",
    "        x_pos_seq = torch.stack(pos_images)\n",
    "        x_neg_seq = torch.stack(neg_images)\n",
    "        \n",
    "        return x_pos_seq, x_neg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d38abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "\n",
    "def build_dataloader(dataset, config):\n",
    "    \"\"\" Build a DataLoader for the EventSequenceDataset. \"\"\"\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=config.shuffle, num_workers=config.num_workers, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "dataset = EventSequenceDataset(config)\n",
    "dataloader = build_dataloader(dataset, config)\n",
    "\n",
    "# 实例化 DataLoader\n",
    "\n",
    "print(\"\\n--- 开始从 DataLoader 中取出一个批次的数据 ---\")\n",
    "\n",
    "# 从迭代器中获取一个批次\n",
    "try:\n",
    "    x_pos_batch, x_neg_batch = next(iter(dataloader))\n",
    "    \n",
    "    print(f\"成功取出一个批次！\")\n",
    "    print(f\"x_pos_batch 的形状: {x_pos_batch.shape}\")\n",
    "    print(f\"x_neg_batch 的形状: {x_neg_batch.shape}\")\n",
    "\n",
    "    # 验证形状\n",
    "    expected_shape = (config.batch_size, config.max_seq_len, 3, 200, 200)\n",
    "    if x_pos_batch.shape == expected_shape and x_neg_batch.shape == expected_shape:\n",
    "        print(\"✅ 批次形状符合预期！\")\n",
    "    else:\n",
    "        print(\"❌ 批次形状不匹配。\")\n",
    "        \n",
    "except StopIteration:\n",
    "    print(\"错误：DataLoader 为空，无法取出数据。请检查数据集路径和内容。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import torch\n",
    "print(accelerate.__version__)\n",
    "print(torch.__version__)\n",
    "\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.bfloat16)\n",
    "print(a, a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def KL(p,q):\n",
    "    # p,q 为两个 list，表示对应取值的概率 且 sum(p) == 1 ，sum(q) == 1\n",
    "    return sum(_p*math.log(_p/_q) for (_p,_q) in zip(p,q) if _p != 0 )\n",
    "\n",
    "P = [0.2, 0.4, 0.4]\n",
    "Q = [0.2, 0.4, 0.4]\n",
    "\n",
    "print(KL(P,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from src.net import build_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# config.use_cuda = False\n",
    "\n",
    "if torch.cuda.is_available() and config.use_cuda:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_num_threads(8) \n",
    "\n",
    "model = build_model(config).to(device)\n",
    "model.eval()\n",
    "\n",
    "weight_path = os.path.join(config.weight_dir, \"event_bert_mlm\" + \".pth\")\n",
    "if os.path.exists(weight_path):\n",
    "    model.load_state_dict(torch.load(weight_path, map_location='cpu'), strict=False)\n",
    "    logger.info(f\"Loading pretrained weights from {weight_path}\")\n",
    "else:\n",
    "    logger.warning(f\"Pretrained weights not found at {weight_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91aec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "captured_outputs = []\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    \"\"\"\n",
    "    一个前向钩子函数。\n",
    "    每次模块(module)的forward被调用后，此函数会被触发。\n",
    "    'output' 就是我们想要的 eventImg2Token 的输出结果。\n",
    "    \"\"\"\n",
    "    # 我们将输出从GPU移到CPU并分离计算图，以防内存泄漏\n",
    "    captured_outputs.append(output.detach().cpu())\n",
    "\n",
    "target_module = model.eventImg2Token\n",
    "handle = target_module.register_forward_hook(forward_hook)    \n",
    "\n",
    "num_test_loops = 20  # 我们测试20个不同的随机输入\n",
    "with torch.no_grad(): # 确保不计算梯度\n",
    "    for _ in tqdm(range(num_test_loops), desc=\"Diagnosing Collapse\"):\n",
    "        # 在每次循环中创建全新的随机输入\n",
    "        mock_x_pos = torch.randn(1, config.max_seq_len, 3, 200, 200) *2 -1\n",
    "        mock_x_neg = torch.randn(1, config.max_seq_len, 3, 200, 200) *2 -1\n",
    "        \n",
    "        # 正常调用模型。当我们调用它时，钩子会自动被触发\n",
    "        model(mock_x_pos.to(device), mock_x_neg.to(device), config.mask_probability)\n",
    "\n",
    "# --- 分析捕获到的数据 ---\n",
    "if captured_outputs:\n",
    "    # 将所有捕获到的输出张量拼接在一起\n",
    "    # 每个输出的形状是 (1, S, token_len)，拼接后是 (num_test_loops, S, token_len)\n",
    "    all_outputs = torch.cat(captured_outputs, dim=0)\n",
    "\n",
    "    # 对logits进行softmax，转换为概率分布\n",
    "    all_probs = torch.softmax(all_outputs, dim=-1)\n",
    "\n",
    "    # 计算在“样本”维度(dim=0)上的标准差\n",
    "    stdev_across_samples = all_probs.std(dim=0)\n",
    "    mean_stdev = stdev_across_samples.mean().item()\n",
    "\n",
    "    logger.info(f\"--- Diagnosis Result ---\")\n",
    "    logger.info(f\"Mean Standard Deviation of softmax outputs across {num_test_loops} random inputs: {mean_stdev:.8f}\")\n",
    "\n",
    "    if mean_stdev < 1e-4: # 一个非常低的阈值\n",
    "        logger.error(\"!!! CRITICAL: Representation Collapse DETECTED.\")\n",
    "        logger.info(\"The model produces nearly identical probability distributions for different random inputs.\")\n",
    "        \n",
    "        # 亲眼看看证据\n",
    "        logger.info(\"Displaying softmax probability of the first token from the first 3 random inputs:\")\n",
    "        for i in range(min(3, num_test_loops)):\n",
    "            # 打印第一个样本，第一个token，前10个值的概率\n",
    "            print(f\"Random Input {i+1}: {all_probs[i, 0, :10]}...\")\n",
    "    else:\n",
    "        logger.info(\"OK: No obvious sign of representation collapse. The model produces diverse outputs.\")\n",
    "else:\n",
    "    logger.warning(\"Hook did not capture any outputs.\")\n",
    "\n",
    "# --- 4. 事后清理：移除钩子 ---\n",
    "# 这是一个好习惯，防止钩子在后续代码中继续产生影响\n",
    "handle.remove()\n",
    "logger.info(\"Hook removed.\")\n",
    "\n",
    "del model\n",
    "del mock_x_pos\n",
    "del mock_x_neg \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "num_vectors = all_outputs.size(0) * all_outputs.size(1)\n",
    "token_dimension = all_outputs.size(2)\n",
    "\n",
    "all_vectors_flat = all_outputs.view(num_vectors, token_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0606e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_tsne(vectors: torch.Tensor):\n",
    "    \"\"\"\n",
    "    使用t-SNE对向量进行二维可视化。\n",
    "    \"\"\"\n",
    "    logger.info(\"--- t-SNE Visualization ---\")\n",
    "    logger.info(\"Running t-SNE... this may take a moment.\")\n",
    "    \n",
    "    # t-SNE需要numpy数组\n",
    "    vectors_np = vectors.cpu().numpy()\n",
    "    \n",
    "    tsne = TSNE(n_components=2, perplexity=15, learning_rate='auto', init='random')\n",
    "    vectors_2d = tsne.fit_transform(vectors_np)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], alpha=0.6)\n",
    "    plt.title(\"t-SNE Visualization of Output Vectors\")\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    # 保存图像而不是显示\n",
    "    # plt.savefig(\"tsne_visualization.png\")\n",
    "    # logger.info(\"t-SNE visualization saved to tsne_visualization.png\")\n",
    "\n",
    "visualize_tsne(all_vectors_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def analyze_cosine_similarity(vectors: torch.Tensor):\n",
    "    \"\"\"\n",
    "    分析一批向量的平均余弦相似度。\n",
    "    Args:\n",
    "        vectors (torch.Tensor): 形状为 (N, D) 的向量，N是样本数，D是向量维度。\n",
    "    \"\"\"\n",
    "    # 1. 对向量进行L2归一化\n",
    "    vectors_normalized = F.normalize(vectors, p=2, dim=1)\n",
    "    \n",
    "    # 2. 计算所有成对的余弦相似度\n",
    "    # (N, D) x (D, N) -> (N, N) 的相似度矩阵\n",
    "    cosine_matrix = torch.matmul(vectors_normalized, vectors_normalized.t())\n",
    "    \n",
    "    # 3. 提取上三角部分（不包括对角线），计算平均值\n",
    "    # 对角线上的值总是1（自己和自己的相似度），需要排除\n",
    "    N = vectors.size(0)\n",
    "    # 创建一个上三角掩码\n",
    "    mask = torch.triu(torch.ones(N, N), diagonal=1).bool()\n",
    "    # 提取所有成对相似度值\n",
    "    pairwise_similarities = cosine_matrix[mask]\n",
    "    \n",
    "    # 4. 计算平均值和标准差\n",
    "    avg_cosine_sim = pairwise_similarities.mean().item()\n",
    "    std_cosine_sim = pairwise_similarities.std().item()\n",
    "\n",
    "    logger.info(f\"--- Cosine Similarity Analysis ---\")\n",
    "    logger.info(f\"Average pairwise cosine similarity: {avg_cosine_sim:.6f}\")\n",
    "    logger.info(f\"Std dev of cosine similarity: {std_cosine_sim:.6f}\")\n",
    "\n",
    "    if avg_cosine_sim > 0.99: # 设置一个非常高的阈值\n",
    "        logger.error(\"!!! CRITICAL: Representation Collapse DETECTED via Cosine Similarity.\")\n",
    "        logger.error(\"Vectors are pointing in nearly the same direction.\")\n",
    "    else:\n",
    "        logger.info(\"OK: Cosine similarity analysis shows no sign of collapse.\")\n",
    "\n",
    "analyze_cosine_similarity(all_vectors_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
