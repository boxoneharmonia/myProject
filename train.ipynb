{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ccd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "INFO:__main__:Starting training with bf16 mixed precision.\n",
      "INFO:__main__:Random seed value: 42\n",
      "INFO:__main__:Weight saved at: ./weight\n",
      "INFO:__main__:Net created successfully.\n",
      "INFO:__main__:Model parameters: 118835544\n",
      "INFO:__main__:Model trainable parameters: 118835544\n",
      "INFO:__main__:Optimizer: adamw, Learning rate: 0.0001\n",
      "INFO:src.dataset:Dataset initialized with 43896 sequences from ./dataset/pretrainv2.\n",
      "INFO:__main__:Train dataloader created with 1567 batches.\n",
      "INFO:__main__:polynomial scheduler created with 75 epochs.\n",
      "/home/box/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "Epoch: 1, Batch: [ 783/783 ], LR: 0.00000000, Loss: 0.303644 (Avg: 1.138369), 0.742585 (Avg: 2.136150), Elapsed: 565.55 ms\n",
      "/home/box/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "Epoch: 2, Batch: [ 783/783 ], LR: 0.00002668, Loss: 0.240666 (Avg: 0.226808), 0.319155 (Avg: 0.476253), Elapsed: 566.06 ms\n",
      "Epoch: 3, Batch: [ 783/783 ], LR: 0.00005337, Loss: 0.233865 (Avg: 0.218101), 0.464129 (Avg: 0.461301), Elapsed: 565.50 ms\n",
      "Epoch: 4, Batch: [ 783/783 ], LR: 0.00008005, Loss: 0.224626 (Avg: 0.223326), 0.478267 (Avg: 0.470625), Elapsed: 556.48 ms\n",
      "Epoch: 5, Batch: [ 783/783 ], LR: 0.00009929, Loss: 0.235640 (Avg: 0.218031), 0.541723 (Avg: 0.463028), Elapsed: 552.67 ms\n",
      "Epoch: 6, Batch: [ 783/783 ], LR: 0.00009652, Loss: 0.222907 (Avg: 0.219445), 0.507052 (Avg: 0.464550), Elapsed: 566.80 ms\n",
      "Epoch: 7, Batch: [ 783/783 ], LR: 0.00009378, Loss: 0.202196 (Avg: 0.218801), 0.418698 (Avg: 0.461253), Elapsed: 569.52 ms\n",
      "Epoch: 8, Batch: [ 783/783 ], LR: 0.00009108, Loss: 0.226106 (Avg: 0.218683), 0.507153 (Avg: 0.464889), Elapsed: 553.51 ms\n",
      "Epoch: 9, Batch: [ 783/783 ], LR: 0.00008842, Loss: 0.223940 (Avg: 0.218490), 0.517191 (Avg: 0.460732), Elapsed: 555.31 ms\n",
      "Epoch: 10, Batch: [ 783/783 ], LR: 0.00008581, Loss: 0.246763 (Avg: 0.218446), 0.481210 (Avg: 0.462081), Elapsed: 557.82 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 11, Batch: [ 783/783 ], LR: 0.00008323, Loss: 0.213957 (Avg: 0.218903), 0.477448 (Avg: 0.462307), Elapsed: 560.16 ms\n",
      "Epoch: 12, Batch: [ 783/783 ], LR: 0.00008069, Loss: 0.277545 (Avg: 0.218678), 0.546656 (Avg: 0.459960), Elapsed: 555.87 ms\n",
      "Epoch: 13, Batch: [ 783/783 ], LR: 0.00007819, Loss: 0.239618 (Avg: 0.218223), 0.468341 (Avg: 0.462806), Elapsed: 556.32 ms\n",
      "Epoch: 14, Batch: [ 783/783 ], LR: 0.00007572, Loss: 0.228421 (Avg: 0.219107), 0.471778 (Avg: 0.463483), Elapsed: 554.62 ms\n",
      "Epoch: 15, Batch: [ 783/783 ], LR: 0.00007330, Loss: 0.194023 (Avg: 0.218928), 0.364026 (Avg: 0.462624), Elapsed: 557.92 ms\n",
      "Epoch: 16, Batch: [ 783/783 ], LR: 0.00007092, Loss: 0.218251 (Avg: 0.219491), 0.465685 (Avg: 0.463852), Elapsed: 556.34 ms\n",
      "Epoch: 17, Batch: [ 783/783 ], LR: 0.00006858, Loss: 0.222523 (Avg: 0.218425), 0.513163 (Avg: 0.463986), Elapsed: 555.53 ms\n",
      "Epoch: 18, Batch: [ 783/783 ], LR: 0.00006627, Loss: 0.229923 (Avg: 0.218897), 0.387414 (Avg: 0.463047), Elapsed: 557.92 ms\n",
      "Epoch: 19, Batch: [ 783/783 ], LR: 0.00006401, Loss: 0.185797 (Avg: 0.218499), 0.444513 (Avg: 0.465278), Elapsed: 554.19 ms\n",
      "Epoch: 20, Batch: [ 783/783 ], LR: 0.00006179, Loss: 0.223664 (Avg: 0.219482), 0.467675 (Avg: 0.462478), Elapsed: 554.92 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 21, Batch: [ 783/783 ], LR: 0.00005960, Loss: 0.225230 (Avg: 0.219036), 0.525081 (Avg: 0.462183), Elapsed: 556.18 ms\n",
      "Epoch: 22, Batch: [ 783/783 ], LR: 0.00005745, Loss: 0.254377 (Avg: 0.218075), 0.554903 (Avg: 0.459690), Elapsed: 558.26 ms\n",
      "Epoch: 23, Batch: [ 783/783 ], LR: 0.00005535, Loss: 0.271472 (Avg: 0.217997), 0.398384 (Avg: 0.464695), Elapsed: 558.56 ms\n",
      "Epoch: 24, Batch: [ 783/783 ], LR: 0.00005328, Loss: 0.202257 (Avg: 0.217928), 0.386156 (Avg: 0.460801), Elapsed: 557.53 ms\n",
      "Epoch: 25, Batch: [ 783/783 ], LR: 0.00005125, Loss: 0.213778 (Avg: 0.218076), 0.470947 (Avg: 0.462184), Elapsed: 556.50 ms\n",
      "Epoch: 26, Batch: [ 783/783 ], LR: 0.00004927, Loss: 0.200073 (Avg: 0.218641), 0.355832 (Avg: 0.463221), Elapsed: 561.08 ms\n",
      "Epoch: 27, Batch: [ 783/783 ], LR: 0.00004732, Loss: 0.221220 (Avg: 0.218531), 0.407850 (Avg: 0.463619), Elapsed: 555.68 ms\n",
      "Epoch: 28, Batch: [ 783/783 ], LR: 0.00004541, Loss: 0.212839 (Avg: 0.218352), 0.438176 (Avg: 0.463479), Elapsed: 556.46 ms\n",
      "Epoch: 29, Batch: [ 783/783 ], LR: 0.00004354, Loss: 0.182963 (Avg: 0.217911), 0.438785 (Avg: 0.462825), Elapsed: 555.67 ms\n",
      "Epoch: 30, Batch: [ 783/783 ], LR: 0.00004171, Loss: 0.221294 (Avg: 0.219078), 0.418562 (Avg: 0.466235), Elapsed: 556.74 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 31, Batch: [ 783/783 ], LR: 0.00003992, Loss: 0.227495 (Avg: 0.218257), 0.557397 (Avg: 0.464625), Elapsed: 556.87 ms\n",
      "Epoch: 32, Batch: [ 783/783 ], LR: 0.00003816, Loss: 0.206279 (Avg: 0.218118), 0.442265 (Avg: 0.462588), Elapsed: 555.00 ms\n",
      "Epoch: 33, Batch: [ 783/783 ], LR: 0.00003645, Loss: 0.204314 (Avg: 0.217633), 0.498105 (Avg: 0.463384), Elapsed: 554.45 ms\n",
      "Epoch: 34, Batch: [ 783/783 ], LR: 0.00003478, Loss: 0.238263 (Avg: 0.217808), 0.570765 (Avg: 0.463284), Elapsed: 557.91 ms\n",
      "Epoch: 35, Batch: [ 783/783 ], LR: 0.00003315, Loss: 0.203666 (Avg: 0.218135), 0.557833 (Avg: 0.465770), Elapsed: 557.85 ms\n",
      "Epoch: 36, Batch: [ 783/783 ], LR: 0.00003155, Loss: 0.204799 (Avg: 0.217937), 0.426006 (Avg: 0.457361), Elapsed: 555.82 ms\n",
      "Epoch: 37, Batch: [ 783/783 ], LR: 0.00003000, Loss: 0.203620 (Avg: 0.218724), 0.419564 (Avg: 0.464784), Elapsed: 555.91 ms\n",
      "Epoch: 38, Batch: [ 783/783 ], LR: 0.00002848, Loss: 0.224336 (Avg: 0.217795), 0.449108 (Avg: 0.464295), Elapsed: 557.65 ms\n",
      "Epoch: 39, Batch: [ 783/783 ], LR: 0.00002701, Loss: 0.225772 (Avg: 0.218739), 0.516325 (Avg: 0.462311), Elapsed: 556.26 ms\n",
      "Epoch: 40, Batch: [ 783/783 ], LR: 0.00002557, Loss: 0.220209 (Avg: 0.218537), 0.418795 (Avg: 0.461673), Elapsed: 556.87 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 41, Batch: [ 783/783 ], LR: 0.00002417, Loss: 0.184755 (Avg: 0.219395), 0.495179 (Avg: 0.467281), Elapsed: 555.14 ms\n",
      "Epoch: 42, Batch: [ 783/783 ], LR: 0.00002281, Loss: 0.193466 (Avg: 0.218430), 0.386791 (Avg: 0.460528), Elapsed: 555.30 ms\n",
      "Epoch: 43, Batch: [ 783/783 ], LR: 0.00002150, Loss: 0.228796 (Avg: 0.218219), 0.389138 (Avg: 0.462939), Elapsed: 561.35 ms\n",
      "Epoch: 44, Batch: [ 783/783 ], LR: 0.00002022, Loss: 0.214772 (Avg: 0.219425), 0.373818 (Avg: 0.464288), Elapsed: 557.31 ms\n",
      "Epoch: 45, Batch: [ 783/783 ], LR: 0.00001898, Loss: 0.213630 (Avg: 0.218259), 0.316446 (Avg: 0.459280), Elapsed: 557.11 ms\n",
      "Epoch: 46, Batch: [ 783/783 ], LR: 0.00001778, Loss: 0.196635 (Avg: 0.218091), 0.613101 (Avg: 0.462892), Elapsed: 554.74 ms\n",
      "Epoch: 47, Batch: [ 783/783 ], LR: 0.00001662, Loss: 0.210630 (Avg: 0.218193), 0.308470 (Avg: 0.462654), Elapsed: 557.49 ms\n",
      "Epoch: 48, Batch: [ 783/783 ], LR: 0.00001550, Loss: 0.200495 (Avg: 0.218455), 0.316225 (Avg: 0.462808), Elapsed: 555.73 ms\n",
      "Epoch: 49, Batch: [ 783/783 ], LR: 0.00001441, Loss: 0.206322 (Avg: 0.218624), 0.297508 (Avg: 0.460312), Elapsed: 557.37 ms\n",
      "Epoch: 50, Batch: [ 783/783 ], LR: 0.00001337, Loss: 0.236717 (Avg: 0.218616), 0.409631 (Avg: 0.466267), Elapsed: 557.99 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 51, Batch: [ 783/783 ], LR: 0.00001237, Loss: 0.218629 (Avg: 0.217985), 0.457513 (Avg: 0.460546), Elapsed: 555.78 ms\n",
      "Epoch: 52, Batch: [ 783/783 ], LR: 0.00001140, Loss: 0.225817 (Avg: 0.218203), 0.375112 (Avg: 0.462970), Elapsed: 554.64 ms\n",
      "Epoch: 53, Batch: [ 783/783 ], LR: 0.00001048, Loss: 0.237323 (Avg: 0.218240), 0.452934 (Avg: 0.465817), Elapsed: 557.55 ms\n",
      "Epoch: 54, Batch: [ 783/783 ], LR: 0.00000960, Loss: 0.224614 (Avg: 0.218244), 0.403567 (Avg: 0.460855), Elapsed: 554.63 ms\n",
      "Epoch: 55, Batch: [ 783/783 ], LR: 0.00000875, Loss: 0.219019 (Avg: 0.218480), 0.539332 (Avg: 0.458927), Elapsed: 557.44 ms\n",
      "Epoch: 56, Batch: [ 783/783 ], LR: 0.00000794, Loss: 0.204049 (Avg: 0.218401), 0.472092 (Avg: 0.460319), Elapsed: 554.35 ms\n",
      "Epoch: 57, Batch: [ 783/783 ], LR: 0.00000718, Loss: 0.237229 (Avg: 0.218804), 0.613863 (Avg: 0.463243), Elapsed: 553.72 ms\n",
      "Epoch: 58, Batch: [ 783/783 ], LR: 0.00000645, Loss: 0.208000 (Avg: 0.218365), 0.571644 (Avg: 0.464247), Elapsed: 552.67 ms\n",
      "Epoch: 59, Batch: [ 783/783 ], LR: 0.00000576, Loss: 0.211832 (Avg: 0.218683), 0.364550 (Avg: 0.464605), Elapsed: 554.30 ms\n",
      "Epoch: 60, Batch: [ 783/783 ], LR: 0.00000511, Loss: 0.245323 (Avg: 0.218786), 0.518873 (Avg: 0.465313), Elapsed: 555.41 ms\n",
      "INFO:__main__:Model weights saved at ./weight/event_bert_v2.pth\n",
      "Epoch: 61, Batch: [ 783/783 ], LR: 0.00000451, Loss: 0.234777 (Avg: 0.218544), 0.479487 (Avg: 0.461928), Elapsed: 559.50 ms\n",
      "Epoch: 62, Batch: [ 783/783 ], LR: 0.00000394, Loss: 0.240795 (Avg: 0.218397), 0.356942 (Avg: 0.465267), Elapsed: 554.73 ms\n",
      "Epoch: 63, Batch: [ 783/783 ], LR: 0.00000341, Loss: 0.222633 (Avg: 0.218532), 0.407006 (Avg: 0.460868), Elapsed: 556.14 ms\n",
      "Epoch: 64, Batch: [ 783/783 ], LR: 0.00000292, Loss: 0.194810 (Avg: 0.218789), 0.325689 (Avg: 0.463222), Elapsed: 556.10 ms\n",
      "Epoch: 65, Batch: [ 783/783 ], LR: 0.00000246, Loss: 0.171152 (Avg: 0.218236), 0.408157 (Avg: 0.460212), Elapsed: 553.38 ms\n",
      "W0810 12:41:30.463000 541003 torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0810 12:41:30.464000 541003 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 541178 closing signal SIGINT\n",
      "W0810 12:41:30.464000 541003 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 541179 closing signal SIGINT\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/home/box/ELOPE/train.py\", line 94, in <module>\n",
      "[rank1]:     main() \n",
      "[rank1]:   File \"/home/box/ELOPE/train.py\", line 72, in main\n",
      "[rank1]:     train_one_epoch(\n",
      "[rank1]:   File \"/home/box/ELOPE/src/trainer.py\", line 33, in train_one_epoch\n",
      "[rank1]:     for batch_idx, x_seq in enumerate(dataloader):\n",
      "[rank1]:   File \"/home/box/.local/lib/python3.10/site-packages/accelerate/data_loader.py\", line 577, in __iter__\n",
      "[rank1]:     current_batch = send_to_device(current_batch, self.device, non_blocking=self._non_blocking)\n",
      "[rank1]:   File \"/home/box/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 153, in send_to_device\n",
      "[rank1]:     return tensor.to(device, non_blocking=non_blocking)\n",
      "[rank1]: KeyboardInterrupt\n",
      "^C\n",
      "W0810 12:41:30.513000 541003 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 541178 closing signal SIGTERM\n",
      "W0810 12:41:30.513000 541003 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 541179 closing signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "!accelerate launch train.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
